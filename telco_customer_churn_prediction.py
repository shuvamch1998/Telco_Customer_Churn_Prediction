# -*- coding: utf-8 -*-
"""Telco_Customer_Churn_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PNcBJ3cAa1Yz0jAaoAcRicy-EHXP6G4Q
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBRFClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

df = pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")
df.head()

df.info()

df.describe()

df.shape

df = df.drop(columns = ["customerID"])

for col in df.columns:
  print(col, df[col].unique())

df.isnull().sum()

len(df[df["TotalCharges"] == " "])

df["TotalCharges"] = df["TotalCharges"].replace({" ": 0.0})

df["TotalCharges"] = df["TotalCharges"].astype(float)

df["Churn"].value_counts()                  #Class imbalance present

def plot_histogram(df, column_name):
  plt.figure(figsize = (5, 3))
  sns.histplot(df[column_name], kde = True)
  plt.title(f"Distribution of {column_name}")

  col_mean = df[column_name].mean()
  col_median = df[column_name].median()

  plt.axvline(col_mean, color = "red", linestyle = "--", label = "Mean")
  plt.axvline(col_median, color = "red", linestyle = "-", label = "Median")

  plt.legend()


  plt.show()

plot_histogram(df, "tenure")

plot_histogram(df, "MonthlyCharges")

plot_histogram(df, "TotalCharges")

plt.figure(figsize = (8, 4))
sns.heatmap(df[["tenure", "MonthlyCharges", "TotalCharges"]].corr(), annot = True, cmap = "coolwarm", fmt = ".2f")
plt.title("correlaton Heatmap")
plt.show()

object_cols = df.select_dtypes(include = 'object').columns.to_list()

object_cols = ["SeniorCitizen"] + object_cols

for col in object_cols:
  plt.figure(figsize = (5, 3))
  sns.countplot(x = df[col])
  plt.title(f"Count plot of {col}")
  plt.show()

df["Churn"] = df["Churn"].replace({"Yes":1, "No":0})

object_columns = df.select_dtypes(include = "object").columns

import pickle

encoders = {}

for column in object_columns:
  label_encoder = LabelEncoder()
  df[column] = label_encoder.fit_transform(df[column])
  encoders[column] = label_encoder


with open ("encoders.pkl", "wb") as f:
  pickle.dump(encoders, f)

df.head()

X = df.drop(columns = ["Churn"])
y = df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

y_train.value_counts()

smote = SMOTE(random_state = 42)

X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

y_train_smote.shape

models = {
    "Decision Tree": DecisionTreeClassifier(random_state = 42),
    "Random Forest": RandomForestClassifier(random_state = 42),
    "XGBoost": XGBRFClassifier(random_state = 42)
}

cv_scores = {}
for model_name, model in models.items():
  scores = cross_val_score(model, X_train_smote, y_train_smote, cv=5, scoring = "accuracy")
  cv_scores[model_name] = scores
  print(f"{model_name} cross_validation_accuracy: {np.mean(scores): .2f}")

cv_scores

rfc = RandomForestClassifier(random_state = 42)

rfc.fit(X_train_smote, y_train_smote)

y_test_pred = rfc.predict(X_test)

print("Accuracy Score:\n", accuracy_score(y_test, y_test_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
print("Classification Report:\n", classification_report(y_test, y_test_pred))

#save the trained model as a pickle file
model_data = {"model": rfc, "features_names": X.columns.tolist()}
with open("customer_churn_model", "wb") as f:
  pickle.dump(model_data, f)

#Load the saved model and the label encoders

with open("customer_churn_model", "rb") as f:
  model_data = pickle.load(f)

loaded_model = model_data["model"]
features_names = model_data["features_names"]

